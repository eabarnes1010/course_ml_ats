{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QQ0q47JvgwX"
   },
   "source": [
    "# Random Forest Example using atmospheric data from Christman Field\n",
    "\n",
    "* Iris example adapted from: https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "* Further modified by: Aaron Hill and Wei-Ting Hsiao (Dept. of Atmospheric Science, Colorado State University), January 2020\n",
    "* Further adapted by: Prof. Elizabeth Barnes for ATS 780A7 Spring 2022 at Colorado State University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V55BtYqA52O"
   },
   "source": [
    "Lets import some libraries we will need throughout this tutorial:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1640970573010,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "YQUUpem1c3tt",
    "outputId": "e59bd3dc-e695-4115-c765-e6424cddddcd"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "print('IN_COLAB = ' + str(IN_COLAB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1640970573298,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "TLuuXcBoA5TN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1640970573299,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "tO0J_hp2NGIn",
    "outputId": "a4a80a74-00f8-441f-8cfb-cd2406a047cf"
   },
   "outputs": [],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"scikit-learn version = {sklearn.__version__}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pq0ubEIlhJ4Y"
   },
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TV70rZ43-A6"
   },
   "source": [
    "### 1.1 Data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_adDXBpYzKN"
   },
   "source": [
    "We have stored a .csv file on a CSU drive, accessible via URL. This will be the basis for our tutorial. This file contains Fort Collins weather data from 2018, and we will use these data to predict the high temperature for a given day with a random forest regression model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1640970573474,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "PlulN6WnZ_K8"
   },
   "outputs": [],
   "source": [
    "# Read in data from url\n",
    "url = \"http://schumacher.atmos.colostate.edu/hilla/temps_FC.csv\"\n",
    "features = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqVhzCoFB2wx"
   },
   "source": [
    "Lets look at our data to see what we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1640970573475,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "ibJ9lUMQB8le",
    "outputId": "d228d76e-0479-4105-eccf-65376ab0c824"
   },
   "outputs": [],
   "source": [
    "# Display first 5 rows\n",
    "print('The shape of our features is:', features.shape)\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXuydX9mB-PT"
   },
   "source": [
    "You will notice we have 365 days of features and labels (complete set from 2018). Our second features axis is the columns of the pandas dataframe. These columns represent the year, month, day, maximum temperature, minimum temperature, max temp from day before, max temp from two days prior, max temperature in Boulder, max temperature in San Francisco, precipitation, and climatological maximum. \n",
    "\n",
    "The max temperature column (TMAX) is actually our label: the observed max temperature at Fort Collins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wwy-d38CtbZ"
   },
   "source": [
    "We can look quickly at some basic statistics of our data, such as mean, standard deviation, percentiles, etc. in a table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1640970573592,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "yZSlkf1u2ZyU",
    "outputId": "a643c515-a117-4875-8d36-6673ea314767"
   },
   "outputs": [],
   "source": [
    "# A handy tool in pandas: descriptive statistics for each column\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfiUkqp6C-co"
   },
   "source": [
    "We have made it so that there is not much to clean up in this dataset...however you may run into a scenario where days are missing, values are missing, etc. wherein you need to remove bad features, labels, or examples (i.e., days of observations). It is often said that 80% of machine learning is the preprocessing of your data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vLWjiNs4OB7"
   },
   "source": [
    "### 1.2 Targets and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsaFBLnKDPbK"
   },
   "source": [
    "The pandas table is handy for a quick glance, but we need to organize some numpy arrays that separately contain our features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1640970573728,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "dlt6GqYwhgnV"
   },
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['TMAX'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features = features.drop('TMAX', axis = 1)\n",
    "\n",
    "# Also remove TMAX_BD for later use, you will understand later\n",
    "features = features.drop('TMAX_BD', axis = 1)\n",
    "\n",
    "# TRY: Add in a random variable to train with some noise\n",
    "#var_rand = np.round(np.random.rand(365)*365)\n",
    "#features['rand'] = var_rand\n",
    "#features.head(5)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pRuZk-AhjAP"
   },
   "source": [
    "### 1.3 Splitting training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95YMbR1YDcqT"
   },
   "source": [
    "Assuming we have no feature data available from 2019 we could use to test our trained models against, we will want to split up our dataset into training and testing portions. A standard proportion is 3/4 for training, 1/4 for testing, although this is somewhat arbitrary here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1640970573729,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "ggg3rkEphk2N"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "# Tunable Parameter: Describes the proportion of the dataset we want to use for testing. 1 - split_size is used for training. \n",
    "split_size = 0.25\n",
    "\n",
    "# PARAMETERS:\n",
    "#     test_size: fraction of testing/validation datasets\n",
    "#     random_state: random parameter\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = split_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfMNcTlSD7sn"
   },
   "source": [
    "Lets quickly check the size of our training and testing arrays are what we expect (and we didn't do something wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1640970573729,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "ZHsogVIIhm5X",
    "outputId": "a216cc81-0505-41b3-8e72-a39dd7fffb29"
   },
   "outputs": [],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmnUiJhK4pQm"
   },
   "source": [
    "# 2. Playing with model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3e98qy3EFiw"
   },
   "source": [
    "OK, our data is now split up into features and labels, as well as training and testing chunks. Now we will work to train and evaluate our model.\n",
    "\n",
    "First, we need to know what our baseline skill is. Often, climatology is used and we will do just that, taking the climatological high temperature from the test features and evaluating it against the test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBGjm_YfhrFa"
   },
   "source": [
    "### 2.1 Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1640970573730,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "noqg8gJBhr9T",
    "outputId": "bda1a38d-1f59-4854-9db4-0059dee209f1"
   },
   "outputs": [],
   "source": [
    "# You need a baseline to quantify whether the model is useful\n",
    "\n",
    "# The baseline predictions here are the climatological values\n",
    "# Grab all rows for the 'TMAX_CLIM' column\n",
    "baseline_preds = test_features[:, feature_list.index('TMAX_CLIM')]\n",
    "\n",
    "# Baseline errors (mean absolute errors)\n",
    "mae_baseline_errors = abs(baseline_preds - test_labels)\n",
    "print('Baseline error (MAE): ', round(np.mean(mae_baseline_errors), 2))\n",
    "\n",
    "# Baseline errors (mean squared errors)\n",
    "mse_baseline_errors = np.sqrt(np.mean((baseline_preds - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round(mse_baseline_errors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tXyAv3cE44l"
   },
   "source": [
    "Subjectively, these errors seem quite high, but as one might expect when trying to predict high temperatures from climatology. I think we can improve upon this with a RF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpPHSkx3huwy"
   },
   "source": [
    "### 2.2 Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbua1xNdbm3M"
   },
   "source": [
    "As mentioned in the slides, there are a number of hyperparameters for RF models that we can tweak and tune to make the model perform better. We will start with a base set of hyperparameters that are defaults for the RF regression model in scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1640970573858,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "iJx8TDwJhvqm",
    "outputId": "8c592afd-5119-4cd4-a516-48bb2c3e7dcd"
   },
   "outputs": [],
   "source": [
    "# Tunable Parameters for Model\n",
    "number_of_trees = 10\n",
    "tree_depth = None \n",
    "node_split = 2       # minimum number of training samples needed to split a node\n",
    "leaf_samples = 1     # minimum number of training samples required to make a leaf node\n",
    "criterion = 'squared_error'    # variance reduction, alternatively 'mae'\n",
    "RAND_STATE = 42\n",
    "\n",
    "# Instantiate model with number of decision trees prescribed above\n",
    "# PARAMETERS:\n",
    "#     n_estimators: number of trees/ensembles\n",
    "#     random_state: random seed\n",
    "#     max_depth: maximum depth of each tree\n",
    "#     criterion: evaluation statistic to split a mode, 'mse'  or 'mae'\n",
    "#     min_samples_split: minimum number of samples needed to split a node\n",
    "#     min_samples_leaf: minimum number of samples needed to make a leaf\n",
    "#     for more, see: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = number_of_trees, \n",
    "                           random_state = RAND_STATE,\n",
    "                           min_samples_split = node_split,\n",
    "                           min_samples_leaf = leaf_samples,\n",
    "                           criterion = criterion,\n",
    "                           max_depth = tree_depth)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FihfSUPbcBmr"
   },
   "source": [
    "Just a handful of lines of code to train the model. Easy peasy. Now lets make some predictions from our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0_gSkHrhySe"
   },
   "source": [
    "### 2.3 Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1640970573859,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "nj7-Y8xShz3C",
    "outputId": "ed63c352-7d5f-4fcb-944b-59ddae70e891"
   },
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Use testing set to validate the performance\n",
    "# Print out the mean absolute error (MAE)\n",
    "mae_errors = abs(predictions - test_labels)\n",
    "print('Baseline error (MAE): ', round(np.mean(mae_baseline_errors), 2))\n",
    "print('Error (MAE): ', round(np.mean(mae_errors), 2))\n",
    "\n",
    "# See its performance (mean squared errors)\n",
    "mse_errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(mse_errors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vIWmqSGG0OX"
   },
   "source": [
    "Not too shabby, we have improved our forecast skill by about 1.5 degrees by using an RF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OwHWbD9c6Ox"
   },
   "source": [
    "Question: Does the size of our training/testing samples matter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1640970573860,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "l29CeNBNbnHb"
   },
   "outputs": [],
   "source": [
    "def split_size_impact(sizes=[0.25,0.5]):\n",
    "\n",
    "    for size in sizes:\n",
    "\n",
    "        split_size = size\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = split_size, random_state = RAND_STATE)\n",
    "        number_of_trees = 10\n",
    "        tree_depth = None \n",
    "        node_split = 2       # minimum number of training samples needed to split a node\n",
    "        leaf_samples = 1     # minimum number of training samples required to make a leaf node\n",
    "        criterion = 'squared_error'    # variance reduction, alternatively 'mae'\n",
    "        rf = RandomForestRegressor(n_estimators = number_of_trees, \n",
    "                               random_state = RAND_STATE,\n",
    "                               min_samples_split = node_split,\n",
    "                               min_samples_leaf = leaf_samples,\n",
    "                               criterion = criterion,\n",
    "                               max_depth = tree_depth)\n",
    "        rf.fit(train_features, train_labels);\n",
    "\n",
    "        predictions = rf.predict(test_features)\n",
    "\n",
    "        print('Split size: ',size)\n",
    "        mae_errors = abs(predictions - test_labels)\n",
    "        print('Baseline error (MAE): ', round(np.mean(mae_baseline_errors), 2))\n",
    "        print('Error (MAE): ', round(np.mean(mae_errors), 2))\n",
    "\n",
    "        mse_errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "        print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "        print('Error (MSE): ', round(mse_errors, 2))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcNSYcBsc-Xn"
   },
   "source": [
    "Compute error stats for a range of training/testing samples sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1640970574552,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "J8cTin4Ycc-N",
    "outputId": "01bd5040-604a-4c21-9b6d-f62a5a11ba0f"
   },
   "outputs": [],
   "source": [
    "split_size_impact(sizes=np.arange(0.1,0.8,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Vog87wmdDXo"
   },
   "source": [
    "It looks like, generally, skill only varies by about half a degree from worst and best RF models. Subjectively, not a lot of sensitivity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIS8T6jSG7DA"
   },
   "source": [
    "### 2.4 Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2RDbf-9G_rQ"
   },
   "source": [
    "Now that we have marginally improved our skill, we can try and optimize our forecasts as well. \n",
    "\n",
    "Tunable parameters: \\\\\n",
    "-Number of trees \\\\\n",
    "-Tree Depth \\\\\n",
    "-Minimum number of samples to split a node \\\\\n",
    "-Minimum number of samples to get a leaf \\\\\n",
    "-Splitting criterion (in this case it is MSE or MAE) \\\\\n",
    "-Testing/training lengths \\\\\n",
    "\n",
    "Lets look at some trained models with different parameters and see if we can find an improved RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVOlJb2XHdk2"
   },
   "source": [
    "First, we will increase our number of trees. Other variables should be the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1640970574684,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "LTrSRgUMHg1L",
    "outputId": "a7b4a4d6-5d74-4834-9eaf-a7509ecb54f2"
   },
   "outputs": [],
   "source": [
    "# Started with 10\n",
    "number_of_trees = 70\n",
    "tree_depth = None\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = number_of_trees, random_state = 42,min_samples_split = node_split,min_samples_leaf = leaf_samples,criterion = criterion,max_depth = tree_depth)\n",
    "rf.fit(train_features, train_labels);\n",
    "predictions = rf.predict(test_features)\n",
    "mae_errors = abs(predictions - test_labels)\n",
    "print('Baseline error (MAE): ', round(np.mean(mae_baseline_errors), 2))\n",
    "print('Error (MAE): ', round(np.mean(mae_errors), 2))\n",
    "mse_errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(mse_errors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdLvcTXycyRl"
   },
   "source": [
    "Using increments of 10, we see that MSE is optimal at about 60 or 70 trees. *Now* lets try tree depth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1640970574924,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "fokmCISsH1pi",
    "outputId": "ae6e14b8-e251-45a6-a81c-1cf2423da1a5"
   },
   "outputs": [],
   "source": [
    "#Default was None\n",
    "tree_depth = 14\n",
    "number_of_trees = 70\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = number_of_trees, random_state = 42,min_samples_split = node_split,min_samples_leaf = leaf_samples,criterion = criterion,max_depth = tree_depth)\n",
    "rf.fit(train_features, train_labels);\n",
    "predictions = rf.predict(test_features)\n",
    "mae_errors = abs(predictions - test_labels)\n",
    "print('Baseline error (MAE): ', round(np.mean(mae_baseline_errors), 2))\n",
    "print('Error (MAE): ', round(np.mean(mae_errors), 2))\n",
    "mse_errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(mse_errors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy-WXrHoIUtJ"
   },
   "source": [
    "Skill maximized at a tree depth of 5...but skill was still pretty good at a depth of 14 too. Little sensitivity to depth when number of trees is at 70. \n",
    "Criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1640970575291,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "moE8fAyvIbQR",
    "outputId": "59d9d656-19d5-4dea-b350-569224089a04"
   },
   "outputs": [],
   "source": [
    "# Default = 'squared_error'\n",
    "criterion = 'squared_error'\n",
    "number_of_trees = 70\n",
    "tree_depth = 14\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = number_of_trees, random_state = 42,min_samples_split = node_split,min_samples_leaf = leaf_samples,criterion = criterion,max_depth = tree_depth)\n",
    "rf.fit(train_features, train_labels);\n",
    "predictions = rf.predict(test_features)\n",
    "mae_errors = abs(predictions - test_labels)\n",
    "print('Baseline error (MAE): ', round(np.mean(mae_baseline_errors), 2))\n",
    "print('Error (MAE): ', round(np.mean(mae_errors), 2))\n",
    "mse_errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(mse_errors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDWBVCWyIjWg"
   },
   "source": [
    "Also little sensitivity. Now lets change the minimum number of samples to split a node..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1640970575429,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "azSbnGCbIiCH",
    "outputId": "d76a7189-17b4-495e-99dc-110e1770df56"
   },
   "outputs": [],
   "source": [
    "# Default = 2\n",
    "node_split = 14\n",
    "number_of_trees = 70\n",
    "tree_depth = 14\n",
    "criterion = 'squared_error'\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = number_of_trees, random_state = 42,min_samples_split = node_split,min_samples_leaf = leaf_samples,criterion = criterion,max_depth = tree_depth)\n",
    "rf.fit(train_features, train_labels);\n",
    "predictions = rf.predict(test_features)\n",
    "mae_errors = abs(predictions - test_labels)\n",
    "print('Baseline error (MAE): ', round(np.mean(mae_baseline_errors), 2))\n",
    "print('Error (MAE): ', round(np.mean(mae_errors), 2))\n",
    "mse_errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(mse_errors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm94T_nDJBDa"
   },
   "source": [
    "Local minimum maybe around 14 samples. Finally, lets see if the number of samples in a leaf matters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1640970575429,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "OWq3MU9xJAr-",
    "outputId": "b924feac-ccfd-401a-dba9-974641817601"
   },
   "outputs": [],
   "source": [
    "# Default = 1\n",
    "leaf_samples = 5\n",
    "node_split = 14\n",
    "number_of_trees = 70\n",
    "tree_depth = 14\n",
    "criterion = 'squared_error'\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = number_of_trees, random_state = 42,min_samples_split = node_split,min_samples_leaf = leaf_samples,criterion = criterion,max_depth = tree_depth)\n",
    "rf.fit(train_features, train_labels);\n",
    "predictions = rf.predict(test_features)\n",
    "mae_errors = abs(predictions - test_labels)\n",
    "print('Baseline error (MAE): ', round(np.mean(mae_baseline_errors), 2))\n",
    "print('Error (MAE): ', round(np.mean(mae_errors), 2))\n",
    "mse_errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(mse_errors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2e01IfoJP5x"
   },
   "source": [
    "While I have no clue if this is globally optimized, as we only went through a few permutations while keeping other variables constant, you can get an idea for the strategies to take when trying to optimize your model. In this case, we found the default RF values didn't provide the most optimal model. We were able to increase our predictive skill by about 3/4 of a degree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbL4zHMAJZIT"
   },
   "source": [
    "One thing we have yet to discuss is the selection of our training and testing datasets. In some applications, it might be more appropriate to select your datasets as contiguous chunks, rather than random subsets. Can anything think of why this would be the case???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q75Uz2H8Jjpy"
   },
   "source": [
    "### 2.5 Training Segments and Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLEATk3JJpDv"
   },
   "source": [
    "Lets take the same approach as before, with a segment legnth of 1/4 for testing, but instead of randomly sampling, lets take a contiguous chunk. We will try a couple different chunks too (i.e., cross validate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1640970575543,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "tQldn7EMJoZF",
    "outputId": "7fef0941-0ec2-45e6-ad0d-d284ffa451ef"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "split_size = 0.1      # chunk size for testing\n",
    "train_length = 0.9    # chunk size for training\n",
    "num_cv = 10             # number of cross-validation tests\n",
    "\n",
    "cv_train_features = []\n",
    "cv_train_labels = []\n",
    "cv_test_features = []\n",
    "cv_test_labels = []\n",
    "\n",
    "for i in range(0,num_cv):\n",
    "    if i == (num_cv - 1):  # last chunk is for testing\n",
    "        cv_train_features.append(features[:round(len(features[:,0]) * train_length)])\n",
    "        cv_train_labels.append(labels[:round(len(features[:,0]) * train_length)])\n",
    "\n",
    "        cv_test_features.append(features[round(len(features[:,0]) * train_length):])\n",
    "        cv_test_labels.append(labels[round(len(features[:,0]) * train_length):])\n",
    "    elif i == 0:          # first chunk is for testing\n",
    "        cv_train_features.append(features[round(len(features[:,0])*split_size):])\n",
    "        cv_train_labels.append(labels[round(len(features[:,0])*split_size):])\n",
    "\n",
    "        cv_test_features.append(features[:round(len(features[:,0])*split_size)])\n",
    "        cv_test_labels.append(labels[:round(len(features[:,0])*split_size)])\n",
    "    else:                 # chunk is in the middle of training dataset\n",
    "        chunk_size = round(len(features[:,0]) * split_size)\n",
    "        first_chunk = features[:(i*chunk_size)]\n",
    "        second_chunk = features[((i+1)*chunk_size):]\n",
    "\n",
    "        cv_train_features.append(np.concatenate((first_chunk, second_chunk),axis=0))\n",
    "        cv_train_labels.append(np.append(labels[:(i * chunk_size)], labels[(i + 1) * chunk_size:]))\n",
    "\n",
    "        cv_test_features.append(features[(i * chunk_size):(i + 1) * chunk_size])\n",
    "        cv_test_labels.append(labels[(i * chunk_size):(i + 1) * chunk_size])\n",
    "\n",
    "    print('Chunk :',(i+1))\n",
    "    print('Training Features Shape:', cv_train_features[i].shape)\n",
    "    print('Training Labels Shape:', cv_train_labels[i].shape)\n",
    "    print('Testing Features Shape:', cv_test_features[i].shape)\n",
    "    print('Testing Labels Shape:', cv_test_labels[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9iR58w4k0QJ"
   },
   "source": [
    "Alright, great. Each of our training sets is of equal length, as is the testing sets. Now lets make RF models for each of these using the \"optimized\" config found before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1558,
     "status": "ok",
     "timestamp": 1640970577098,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "6MKztgUXK4iZ",
    "outputId": "1cdc7909-d80c-4c30-d841-2fa30de6e9cd"
   },
   "outputs": [],
   "source": [
    "leaf_samples = 5\n",
    "node_split = 14\n",
    "number_of_trees = 70\n",
    "tree_depth = 5\n",
    "criterion = 'squared_error'\n",
    "\n",
    "cv_predictions = []\n",
    "for i in range(0,num_cv):\n",
    "    cv_rf = RandomForestRegressor(n_estimators = number_of_trees, random_state = 42,min_samples_split = node_split,min_samples_leaf = leaf_samples,criterion = criterion,max_depth = tree_depth)\n",
    "    cv_rf.fit(cv_train_features[i], cv_train_labels[i]);\n",
    "    i_predictions = cv_rf.predict(cv_test_features[i])\n",
    "    cv_predictions.append(i_predictions)\n",
    "    mae_errors = abs(i_predictions - cv_test_labels[i])\n",
    "    print('Model :',(i+1))\n",
    "    print('Baseline error (MAE): ', round(np.mean(mae_baseline_errors), 2))\n",
    "    print('Error (MAE): ', round(np.mean(mae_errors), 2))\n",
    "    mse_errors = np.sqrt(np.mean((i_predictions - cv_test_labels[i])**2))\n",
    "    print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "    print('Error (MSE): ', round(mse_errors, 2))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkQSD1UqlC96"
   },
   "source": [
    "Interestingly, one of our contiguously-trained models outperforms the randomly-sampled model. Lets take a look at what our models are predicting visually with graphs in a time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEEvFIRYiRG7"
   },
   "source": [
    "### 2.6 Visualization of prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWEHUbINmSbC"
   },
   "source": [
    "#### Randomly-sampled trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1640970577099,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "iNT-5sowmb68"
   },
   "outputs": [],
   "source": [
    "def plot_time_series(features, feature_list, labels, test_features, predictions):\n",
    "    # Use datetime for creating date objects for plotting\n",
    "    # Dates of training values\n",
    "    months = features[:, feature_list.index('MONTH')]\n",
    "    days = features[:, feature_list.index('DAY')]\n",
    "    years = features[:, feature_list.index('YEAR')]\n",
    "    # List and then convert to datetime object\n",
    "    dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "    dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "    # Dataframe with true values and dates\n",
    "    true_data = pd.DataFrame(data = {'date': dates, 'TMAX': labels})\n",
    "    # Dates of predictions\n",
    "    months = test_features[:, feature_list.index('MONTH')]\n",
    "    days = test_features[:, feature_list.index('DAY')]\n",
    "    years = test_features[:, feature_list.index('YEAR')]\n",
    "    # Column of dates\n",
    "    test_dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "    # Convert to datetime objects\n",
    "    test_dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in test_dates]\n",
    "    # Dataframe with predictions and dates\n",
    "    predictions_data = pd.DataFrame(data = {'date': test_dates, 'prediction': predictions})\n",
    "    # Plot the actual values\n",
    "    plt.plot(true_data['date'], true_data['TMAX'], 'b-', label = 'TMAX')\n",
    "    # Plot the predicted values\n",
    "    plt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'prediction')\n",
    "    plt.xticks(rotation = '60'); \n",
    "    plt.legend()\n",
    "    # Graph labels\n",
    "    plt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual and Predicted Values');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1640970577671,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "CchwPipRiVxv",
    "outputId": "abba95f2-8b3e-40a6-fecb-c1bae0e5d6be"
   },
   "outputs": [],
   "source": [
    "# Use datetime for creating date objects for plotting\n",
    "# Dates of training values\n",
    "plot_time_series(features, feature_list, labels, test_features, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJgvTfsEmX1q"
   },
   "source": [
    "#### Contiguous Chunk Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2585,
     "status": "ok",
     "timestamp": 1640970580254,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "lZRL7wVNn9nR",
    "outputId": "f99b6a0e-738e-473e-bc34-998ecbe9320a"
   },
   "outputs": [],
   "source": [
    "for i in range(0, num_cv):\n",
    "    print('Model: ',(i+1))\n",
    "    plot_time_series(features, feature_list, labels, cv_test_features[i], cv_predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxLX1ATNpVfy"
   },
   "source": [
    "There may be advantages to organizing your training/testing in this manner, particularly when dealing with examples that are entirely independent from one another, e.g., daily weather patterns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfwo6cnIh_Zz"
   },
   "source": [
    "# VISUALIZATION TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sfs0dlRRiCWy"
   },
   "source": [
    "### 3.1 Visualizing a Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2240,
     "status": "ok",
     "timestamp": 1640970582489,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "KSF3ctHsyv1h",
    "outputId": "9839f2c8-67db-46d7-acbf-d1f8f0742167"
   },
   "outputs": [],
   "source": [
    "if(IN_COLAB==True):\n",
    "    # 1. Make the path of your own Google Drive accessible\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    local_path = '/content/drive/My Drive/Colab Notebooks/'\n",
    "else:\n",
    "    local_path = 'figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1640,
     "status": "ok",
     "timestamp": 1640970584127,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "Z6m0hSHpiBK3"
   },
   "outputs": [],
   "source": [
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[40]\n",
    "filename = 'RF_christman_field_tree'\n",
    "\n",
    "try:\n",
    "    # Export the image to a dot file\n",
    "    export_graphviz(tree, out_file = '{}/{}.dot'.format(local_path, filename), feature_names = feature_list, rounded = True, precision = 1)\n",
    "\n",
    "    # Use dot file to create a graph\n",
    "    (graph, ) = pydot.graph_from_dot_file('{}/{}.dot'.format(local_path, filename))\n",
    "\n",
    "    # Write graph to a png tree\n",
    "    graph.write_png('{}/{}.png'.format(local_path, filename))\n",
    "except:\n",
    "    print('unable to save graph figures.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Lis4L4iiJUY"
   },
   "source": [
    "### 3.2 Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hC1hfqdGuceB"
   },
   "source": [
    "First we will look at Impurity Importance, which is built into Scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1640970584127,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "OgqSVpwwiJ_n"
   },
   "outputs": [],
   "source": [
    "def calc_importances(rf, feature_list):\n",
    "\n",
    "    # Get numerical feature importances\n",
    "    importances = list(rf.feature_importances_)\n",
    "\n",
    "    # List of tuples with variable and importance\n",
    "    feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "    # Sort the feature importances by most important first\n",
    "    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    # Print out the feature and importances \n",
    "    [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1640970584128,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "SwggdvM7iR4T"
   },
   "outputs": [],
   "source": [
    "def plot_feat_importances(importances, feature_list): \n",
    "    plt.figure()\n",
    "    # Set the style\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    # list of x locations for plotting\n",
    "    x_values = list(range(len(importances)))\n",
    "    # Make a bar chart\n",
    "    plt.barh(x_values, importances)\n",
    "    # Tick labels for x axis\n",
    "    plt.yticks(x_values, feature_list)\n",
    "    # Axis labels and title\n",
    "    plt.xlabel('Importance'); plt.ylabel('Variable'); plt.title('Variable Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1640970584758,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "v0Yts2qH-lNP",
    "outputId": "49ca215b-302a-4e82-f31d-accb5d39e299"
   },
   "outputs": [],
   "source": [
    "plot_feat_importances(calc_importances(rf, feature_list), feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T6E9ZRi_qQW"
   },
   "source": [
    "### 3.3 Permutation Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOuejg730XhZ"
   },
   "outputs": [],
   "source": [
    "# Single-pass permutation\n",
    "permute = permutation_importance(rf, test_features, test_labels, n_repeats=10, \n",
    "                                 random_state=42)\n",
    "\n",
    "# Sort the importances\n",
    "sorted_idx = permute.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5RIkCKO1KPE"
   },
   "source": [
    "First, lets look at what is most important in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiXCBDcz0lJN"
   },
   "outputs": [],
   "source": [
    "def plot_perm_importances(permute, sorted_idx, feature_list):\n",
    "  # Sort the feature list based on \n",
    "\n",
    "    new_feature_list = []\n",
    "    for index in sorted_idx:  \n",
    "        new_feature_list.append(feature_list[index])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(permute.importances[sorted_idx].T,\n",
    "           vert=False, labels=new_feature_list)\n",
    "    ax.set_title(\"Permutation Importances\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGEnl3ih_VTI"
   },
   "outputs": [],
   "source": [
    "plot_perm_importances(permute, sorted_idx, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDcXepd01M6K"
   },
   "source": [
    "How about in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Cc5ijQW0iht"
   },
   "outputs": [],
   "source": [
    "permute = permutation_importance(rf, train_features, train_labels, n_repeats=10, random_state=42)\n",
    "sorted_idx = permute.importances_mean.argsort()\n",
    "\n",
    "plot_perm_importances(permute, sorted_idx, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWoFqi8vMzrg"
   },
   "source": [
    "### 3.4 Comparing Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pieVVuxvM3zT"
   },
   "source": [
    "It may be beneficial at times to compare your labels to predictors, which can something explain why certain features are better than others. Lets plot the time series for max temp and a couple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DQnzCQF5Aye"
   },
   "outputs": [],
   "source": [
    "def plot_features(features, variables=['TMAX','TMAX_1d','TMAX_CLIM','TMIN']):\n",
    "    # Make the data accessible for plotting\n",
    "    # Dates of training values\n",
    "    months = features[:, feature_list.index('MONTH')]\n",
    "    days = features[:, feature_list.index('DAY')]\n",
    "    years = features[:, feature_list.index('YEAR')]\n",
    "    # List and then convert to datetime object\n",
    "    dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "    dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "    # Make the data accessible for plotting\n",
    "    true_data = pd.DataFrame(data = {'date': dates, 'TMAX': labels})\n",
    "    true_data[variables[1]] = features[:, feature_list.index(variables[1])]\n",
    "    true_data[variables[2]] = features[:, feature_list.index(variables[2])]\n",
    "    true_data[variables[3]] = features[:, feature_list.index(variables[3])]\n",
    "    # Plot all the data as lines\n",
    "    plt.plot(true_data['date'], true_data['TMAX'], 'b-', label  = 'TMAX', alpha = 1.0)\n",
    "    plt.plot(true_data['date'], true_data[variables[1]], 'y-', label  = variables[1], alpha = 1.0)\n",
    "    plt.plot(true_data['date'], true_data[variables[2]], 'k-', label = variables[2], alpha = 0.8)\n",
    "    plt.plot(true_data['date'], true_data[variables[3]], 'r-', label = variables[3], alpha = 0.3)\n",
    "    # Formatting plot\n",
    "    plt.legend(); plt.xticks(rotation = '60');\n",
    "    # Lables and title\n",
    "    plt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual Max Temp and Variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfX0ZicWiYt0"
   },
   "outputs": [],
   "source": [
    "plot_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utu8XRLm9ZHH"
   },
   "outputs": [],
   "source": [
    "plot_features(features, variables=['TMAX','TMAX_CLIM','TMAX_SF','PRCP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE_yfBvw_xB3"
   },
   "source": [
    "### Extra: Train a Model Using Only a Subset of Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFwijCAhApDS"
   },
   "outputs": [],
   "source": [
    "leaf_samples = 5\n",
    "node_split = 14\n",
    "number_of_trees = 70\n",
    "tree_depth = 5\n",
    "criterion = 'squared_error'\n",
    "\n",
    "#Reload in features to clean things up a bit \n",
    "features = pd.read_csv(url)\n",
    "features = features.drop('TMAX', axis = 1)\n",
    "features = features.drop('TMAX_BD', axis = 1)\n",
    "\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = split_size, random_state = 42)\n",
    "\n",
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators = number_of_trees, \n",
    "                                          random_state = 42,\n",
    "                                          min_samples_split = node_split,\n",
    "                                          min_samples_leaf = leaf_samples,\n",
    "                                          criterion = criterion,\n",
    "                                          max_depth = tree_depth)\n",
    "\n",
    "# Use the top 4 predictors, as determined by feature importance\n",
    "important_indices = [feature_list.index('PRCP'), feature_list.index('TMAX_CLIM'), feature_list.index('TMAX_1d'), feature_list.index('TMIN')]\n",
    "train_important = train_features[:, important_indices]\n",
    "test_important = test_features[:, important_indices]\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_labels)\n",
    "# Make predictions\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "# Display the performance metrics\n",
    "errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(errors, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLp8c0VtNH3B"
   },
   "outputs": [],
   "source": [
    "leaf_samples = 5\n",
    "node_split = 14\n",
    "number_of_trees = 70\n",
    "tree_depth = 5\n",
    "criterion = 'squared_error'\n",
    "\n",
    "#Reload in features to clean things up a bit \n",
    "features = pd.read_csv(url)\n",
    "features = features.drop('TMAX', axis = 1)\n",
    "features = features.drop('TMAX_BD', axis = 1)\n",
    "\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = split_size, random_state = 42)\n",
    "\n",
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators = number_of_trees, \n",
    "                                          random_state = 42,\n",
    "                                          min_samples_split = node_split,\n",
    "                                          min_samples_leaf = leaf_samples,\n",
    "                                          criterion = criterion,\n",
    "                                          max_depth = tree_depth)\n",
    "\n",
    "# Use the top 4 predictors, as determined by permutation importance\n",
    "important_indices = [feature_list.index('PRCP'), feature_list.index('TMAX_CLIM'), feature_list.index('TMAX_SF'), feature_list.index('TMAX_2d')]\n",
    "train_important = train_features[:, important_indices]\n",
    "test_important = test_features[:, important_indices]\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_labels)\n",
    "# Make predictions\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "# Display the performance metrics\n",
    "errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(errors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6g4si8loAUy1"
   },
   "source": [
    "## Extra: Woah Nelly Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FzAgocV7be2"
   },
   "source": [
    "Remember at the very beginning of the tutorial when we withheld Boulder's high temperature? Well lets add that back in and train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3ZT_UG_iOzl"
   },
   "outputs": [],
   "source": [
    "leaf_samples = 5\n",
    "node_split = 14\n",
    "number_of_trees = 70\n",
    "tree_depth = 5\n",
    "criterion = 'squared_error'\n",
    "\n",
    "#Reload in features and don't delete Boulder data\n",
    "features = pd.read_csv(url)\n",
    "features = features.drop('TMAX', axis = 1)\n",
    "\n",
    "# Save this for a little bit...\n",
    "#features = features.drop('TMAX_CLIM', axis = 1)\n",
    "#features = features.drop('PRCP', axis = 1)\n",
    "#features = features.drop('TMAX_SF', axis = 1)\n",
    "#features = features.drop('TMAX_BD', axis = 1)\n",
    "\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "train_important, test_important, train_labels, test_labels = train_test_split(features, labels, test_size = split_size, random_state = 42)\n",
    "\n",
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators = number_of_trees, \n",
    "                                          random_state = 42,\n",
    "                                          min_samples_split = node_split,\n",
    "                                          min_samples_leaf = leaf_samples,\n",
    "                                          criterion = criterion,\n",
    "                                          max_depth = tree_depth)\n",
    "\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_labels)\n",
    "# Make predictions\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "# Display the performance metrics\n",
    "errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(errors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75eRUgSHAZE2"
   },
   "source": [
    "Error is SIGNIFICANTLY reduced. \n",
    "\n",
    "Lets look at predictor importance real quick...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJpdjY4X-Pkb"
   },
   "outputs": [],
   "source": [
    "new_importances = list(rf_most_important.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, new_importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71r7BJc6-tZt"
   },
   "outputs": [],
   "source": [
    "plot_feat_importances(new_importances, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5d7pOE_mucn"
   },
   "outputs": [],
   "source": [
    "# Pull out one tree from the forest\n",
    "tree = rf_most_important.estimators_[40]\n",
    "filename = 'RF_christman_field_most_important_tree'\n",
    "\n",
    "try:\n",
    "    # Export the image to a dot file\n",
    "    export_graphviz(tree, out_file = '{}/{}.dot'.format(local_path, filename), feature_names = feature_list, rounded = True, precision = 1)\n",
    "\n",
    "    # Use dot file to create a graph\n",
    "    (graph, ) = pydot.graph_from_dot_file('{}/{}.dot'.format(local_path, filename))\n",
    "\n",
    "    # Write graph to a png tree\n",
    "    graph.write_png('{}/{}.png'.format(local_path, filename))\n",
    "except:\n",
    "    print('unable to save graph figures.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwkQgYtA_dOQ"
   },
   "outputs": [],
   "source": [
    "permute = permutation_importance(rf_most_important, train_important, train_labels, n_repeats=10 )\n",
    "sorted_idx = permute.importances_mean.argsort()\n",
    "plot_perm_importances(permute, sorted_idx, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hhjr5xJuXaM9"
   },
   "source": [
    "Impurity feature importance suggests that the Boulder observation is extremely important, while the permutation importance thinks the climatology is most important. But if we look at a tree, we can see that the Boulder observation is littered across the top of trees; of course the impurity importance will pick it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VFENf5TnZJ0"
   },
   "source": [
    "What if we trained the model JUST using Boulders high temperature???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CH6UiWOGdAyx"
   },
   "outputs": [],
   "source": [
    "leaf_samples = 5\n",
    "node_split = 14\n",
    "number_of_trees = 70\n",
    "tree_depth = 5\n",
    "criterion = 'squared_error'\n",
    "\n",
    "#Reload in features to clean things up a bit \n",
    "features = pd.read_csv(url)\n",
    "features = features.drop('TMAX', axis = 1)\n",
    "\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = split_size, random_state = 42)\n",
    "\n",
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators = number_of_trees, \n",
    "                                          random_state = 42,\n",
    "                                          min_samples_split = node_split,\n",
    "                                          min_samples_leaf = leaf_samples,\n",
    "                                          criterion = criterion,\n",
    "                                          max_depth = tree_depth)\n",
    "\n",
    "# Use the top 4 predictors, as determined by permutation importance\n",
    "important_indices = [feature_list.index('TMAX_BD')]\n",
    "train_important = train_features[:, important_indices]\n",
    "test_important = test_features[:, important_indices]\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_labels)\n",
    "# Make predictions\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "# Display the performance metrics\n",
    "errors = np.sqrt(np.mean((predictions - test_labels)**2))\n",
    "print('Baseline error (MSE): ', round( mse_baseline_errors, 2))\n",
    "print('Error (MSE): ', round(errors, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dm5E5BwKNGI-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "random_forest_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
